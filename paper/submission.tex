\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
%\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
\setcounter{page}{1}
\begin{document}

%-------------------------------------------------------------------------
\title{Deep Learning for 3D Brain Activity Scans}

\author{Evan Albright\\
University of Massachusetts Amherst\\
140 Governors Dr, Amherst, MA 01002\\
{\tt\small ealbright@umass.edu}
}

\maketitle
%\thispagestyle{empty}

%-------------------------------------------------------------------------
\begin{abstract}
   Abstract placeholder (sub 300 words)
\end{abstract}

% ----------------------------------------------------------------------
% INTRODUCTION
% ----------------------------------------------------------------------
\section{Introduction}\label{sec:introduction}
Neuroimaging presents fertile grounds for deep learning applications, with myriad interesting real world benefits
for mental health research and disease diagnosis.
High dimensional, massive datasets, with intertwining patterns of activity and structure in three or four
dimensions, are a lot to manage by hand.

Classification of activity and structures should come quite naturally with deep learning practices.
Previous works include the development of Restricted Boltzmann Machines, and Deep Belief Networks~\cite{plis2014deep},
yet often only as a proof of concept.
Others are working now to try and find universal architectures for most
neuro-imaging tasks~\cite{henschel2019fastsurfer}, though it seems this is still far from a solved
application with satisfactory performances across the board.

Of more interest to myself, deep learning networks in their proven capacity to segment images based on what entities
they identify in classification could surely be adopted to highlight what patterns of activity have informed their
own decision making and perhaps clue researchers in to overlooked details.

My ambition is to create a highly accurate 3d convolutional network to first classify, then segment brain scans to
help with my specific application of neuroimaging.

I may also attempt to explore feature analysis and reduction which has been shown to
help~\cite{shi2018feature} with deep learning tasks, if only to manage the challenging
dimensionality of their 3d inputs.



% ----------------------------------------------------------------------
% PROBLEM STATEMENT
% ----------------------------------------------------------------------
\section{Problem Statement}\label{sec:problem-statement}

(BACKGROUND / RELATED)

The dataset to be used is a set of neuro-imaging scans from a cohort of 30 healthy, young women in the
Netherlands circa 2013 who were presented with various grids of images featuring
either neutral entities, (e.g.\ office chairs, windows, jackets) or foods~\cite{smeets2013allured}.
The foods were specifically types of calorically dense, tempting foods, which the individuals viewing would likely
have formed restraint with given their success in maintaining healthy body mass indices.
The experiment was meant to highlight brain structures roles in anticipated rewards from consuming delicious foods,
balanced against the hypothesized activation of restraints.
In neuro-imaging, this task is known as passive image viewing.

Given the quite important role of food and willpower in our lives, the activation patterns are likely to be powerful
and distinguishable from neutral objects which we haven't evolved to be nearly as concerned with.
This combination gives me high hopes of success in this specific application of learning to classify the viewed
objects through brain activations of the subjects.

I hope given the clarity in patterns in the brain scans, that I can develop a neural network to highlight what
features and locations in the brain scans have been helpful in informing the decisions of classification, in the
hope that such methods could be adapted to harder tasks in the future.

The dataset can be found from the excellent
OpenNeuro project here: \url{https://openneuro.org/datasets/ds000157/versions/00001}
It consists of a survey detailing the relationship of each subject with food and diet taken after the experimental
proceedings, and the core data of two modalities of brain imaging: a single high resolution T1w brain scan,
and time series of bold scans of about 370-375 scans, which encompasses the approximately 10 minute experiment
in its entirety.
The bold scans are quite sizeable given the number of them, however they are a relatively low resolution, consisting
of 64 sagital by 64 coronal by 30 axial scans.

You may review the full experimental paper as well here: \url{http://www.pamitc.org/documents/mermin.pdf}.

You may find this project repository here: \url{https://github.com/e-m-albright/CS682}
Reading the paper is critical to understanding the format of the dataset, however I hope I will provide enough
abstraction in the project repository for you to be freed of that challenge should you wish to have a look around.



% ----------------------------------------------------------------------
% TECHNICAL APPROACH
% ----------------------------------------------------------------------
\section{Technical Approach}\label{sec:technical-approach}
I intend to explore the efficacy of 3d convolutional networks which have been shown to have a slight performance
edge on 2d convolutions~\cite{payan2015predicting}.
Given the nature of the input images being 3d brain scans this makes intuitive sense and could allow for much more
interesting patterns of brain activity and structuring being recognized.

As for the deeper architecture, I'm hoping to imitate some of the more successful networks like VGG or ResNet,
however I wouldn't be surprised if they don't adapt well to this particular application, especially given how
interesting and important it could be to keep the input data in a three dimensional format.

It is my hope that I can also learn from other developments of object detection to see what regions in the
brain become active for a particular classification, like Faster R-CNN

\subsection{Novelty}\label{subsec:novelty}

I have not seen any application of classification or object segmentation to neuroimaging in 3d
on brain activity patterns.
I have seen some works which I hope to leverage with similar aims like that of structural identification
for tumors, in two dimensions~\cite{akkus2017deep}.
However at the very least I hope to produce a very successful network on my chosen problem first and foremost rather
than assume I am the only person to ever think of something as intuitive as bringing neural networks to bear
on neuro-imaging tasks.

I hope to find a methodology of first classifying correctly the brain scans, improve accuracy as much as possible,
and adapt the approach into tools for identifying important regions of activity in the
brain which are being utilized for classification.

I am not chiefly focused on coping with the challenges of memory but it may become too important to overlook.
Each dataset input is a $64 \times 64 \times 30$ slice of floats, for which we've got
about $375 scans \times 30 subjects$ total.
In my work on preliminary results I have already been confronted by the limitations of my current machine and have
been trying working around the issue until I am ready to attempt to resolve it.
This may be an unavoidable area to simultaneously try to innovate for the field of
neuro-imaging analysis with deep learning


% ----------------------------------------------------------------------
% INTERMEDIATE RESULTS
% ----------------------------------------------------------------------
\section{Intermediate Results}\label{sec:intermediate-results}
At the date of the milestone, I have shown that my experimental set-up is complete to begin
iterating towards the novel contributions aimed for by this project.

I am generally happy with how things are going, and feel optimistic that I will construct a successful neural
network for classification on my chosen dataset incorporating my own contributions to the process.

I hope my goal for region highlighting is also feasible in the time frame with only myself on the task, but I am
excited nevertheless to try.

\subsection{Data}\label{subsec:data}
I have become familiar with the chosen dataset, and created a machine learning friendly format
based off of the data.

I have inferred classification labels from the experimental events timings and the estimated time
of each complete scan in the dataset.

\subsection{Sanity Checks}\label{subsec:sanity-checks}
Using the data, I have implemented a very simple, yet effective 80\% accurate SVM classifier to prove the data
should be ready for use with my chosen deep learning methodologies.

I'm now confident in the classifications of each of the scans (about 375 per subject, for 30 subjects)

\subsection{Deep Learning \& Future Works}\label{subsec:deep-learning}
I have tried feeding the data into very basic neural networks with mixed success, and am in the active process of
troubleshooting.
Once I have matched performance with the SVM using an implementation of a reasonable neural network using PyTorch, I
will begin the process of looking for refinements and innovations alluded to in previous sections, as well as
transitioning the task to object detection if I can.


% ----------------------------------------------------------------------
% TODO
% ----------------------------------------------------------------------
\section{TODO}\label{sec:todo}

NN project
- 2d hyperparameters, let's use a LR scheduler? LR spikes all over the place still, why?

- 3d CNN - typically meant for video classification using time as the third axis,
here we are not using time, though that is a dimension we have access to,
though doesn't make sense for this experiment/project to try to add in
- https://pytorch.org/docs/stable/torchvision/models.html#video-classification

- scheduler / hyperparams / diff architectures (just go with res3d, res2d+1d, mix three types
- cut batch size to avoid scaling down images (TRIED NO BUENO?)

be sure to talk about everything in paper

normalization/mean image
interpolation
wrestling with memory constraints (batch size / 3d data huge for cpu/gpu, dataset pretty large in general for ram) slow learning, tapering off learning
different styles of 1d (unfurl 3d, 2d) 2d (mean flattened, one slice) 3d (scale, orig)
LR explorations
sanity checks on brain image data, impossible for me to spot the differences

batch_size and interpolation hard to juggle too?
3d feels like "luck" plays a big part of getting training to catch/start
seems like scaling down is pretty important and I have better luck with larger batch sizes (meaning scale down is crucial) wonder if aggressive scale down is worthwhile, like over 3./4, image gets real grainy real fast)

images:
LR / accuracy measures, of diff approaches
hi res, mid res, interpolated down res brain scan examples,
2d slice example
total training time? num features comparison
average slice image
graphs from 2d training, 3d takes legit 2-3 hours for 200 epochs on 6 subjects with 5./6 & 7. / 2.

inclusion of more ppts/subjects means more training time (val/test are of same patients,
hence more individual brain shapes means more general, but longer to learn)
20 epochs to see liftoff of 55% with 10 ppts, vs quicker with 6ppts

image segmentation attempt?
saliency maps?
filter views?

torch save models - can eval that way
host for downloads?

future works
better gpu / computer might be important, the 3d models are real fucking beasts to train, and their data is large as fuck
model ensemble (free extra few percent perf)

findings: 3d is cool, but crazy prohibitively slow and not much better than 2d without more refinements. IMHO theres
promise still in exploring it, but given the inexcusable runtime and datasize 2d is probably worth more investment
unless better hardware or serious effort is expended in getting it differentiable

PUT BRAIN SCANS IN SUPPLEMENTARY?

abstract > intro > background > related
methods/approach > results > discussion > references
6 pages? 7 maybe at most

gradual warm-start improvements?
variations on models? meh

unsupervised segmentation - little hard

surprisingly bad results on warm starting expansion to new subjects - old same subjects takes a little while to stabilize
but it gets back to 83% without much fuss, probably LR is a little high to start with and the decay helps a lot.
bounces down for a while, bounces up for a while. breaking 90% which is very cool, might mean warm start has best potential

WORK ON GETTING PARAM NUMBERS AND
DIFFERENT METRICS (AUC PLEASE, F1 PLEASE)
2d is enough

Submit your final submission through OpenReview. You will submit a single pdf file:
A pdf file of your final report

(OPTIONAL) supplementary can be concatenated at the end of the final report
Report. The following is a suggested structure for the report:
Title, Author(s)

Abstract: It should not be more than 300 words

Introduction: this section introduces your problem, and the overall plan for approaching your problem
Background/Related Work: This section discusses relevant literature for your project
Approach: This section details the framework of your project. Be specific, which means you might want to include equations, figures, plots, etc
Experiment: This section begins with what kind of experiments you're doing, what kind of dataset(s) you're using, and what is the way you measure or evaluate your results. It then shows in details the results of your experiments. By details, we mean both quantitative evaluations (show numbers, figures, tables, etc) as well as qualitative results (show images, example results, etc).
Conclusion: What have you learned? Suggest future ideas.
References: This is absolutely necessary.
Supplementary Material is not counted toward your 6-8 page limit. It is optional and is supposed to contain less important results/experiments/etc not critical for understanding the main report.

try different architectures - more depth?
see if we can break 85% to 90%, talk about potential data mislabeling frustration as a barrier to higher results possibly

you are expected to show substantially more experiments and results with NN-related methods
( :(  lame)

11171266 trainable params in resnet18 2d
33148482 trainable params in resnet18 3d (about 2.97x)

data size tho -
30x bigger (30 x 44 x 40) vs (44 x 40)

~\cite{he2016deep} resnet
~\cite{tran2018closer} 3d/time resnet
~\cite{hara3dcnns} 3d cnn pt1?


% ----------------------------------------------------------------------
% END
% ----------------------------------------------------------------------
{\small
\bibliographystyle{ieee}
\bibliography{project}
}

\end{document}
